PS10 Thatcher
rachel.e.thatcher-1
April 2018

Question 9

Optimal values of the tuning parameters for each of the algorithms:
Tree: f1 = .8968, gmean = .6731
Logistic Regression: f1 = .8986, gmean = .6762
Neural Network: f1 = .9059, gmean = .7600
Naive Bayes: f1 = .8826, gmean = .
kNN: f1 = .8985, gmean = .7544
SVM: f1 = .9016, gmean = .7417

How does the out-of-sample performance compare with each of the other
algorithms?
	They all are pretty similar, with f1 being around .90 for most of them and
	gmean being a bit more varied with number ranging from .67 to .76, but still
	fairly close together